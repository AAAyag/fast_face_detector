---------------------------------------------------------------------------
Training stage 0
Sampled 14375 windows from 14375 images.
Done sampling windows (time=532s).
Computing lambdas... done (time=114s).
Extracting features... done (time=36s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=12s).
Extracting features... done (time=6s).
Training AdaBoost: nWeak= 32 nFtrs=5819 pos=28496 neg=5000
 i=  16 alpha=0.317 err=0.346 loss=2.16e-01
 i=  32 alpha=0.311 err=0.349 loss=1.02e-01
Done training err=0.0210 fp=0.0226 fn=0.0194 (t=5.1s).
Done training stage 0 (time=710s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 384 images.
Done sampling windows (time=6048s).
Extracting features... done (time=6s).
Training AdaBoost: nWeak=128 nFtrs=5819 pos=28496 neg=10000
 i=  16 alpha=0.261 err=0.372 loss=3.77e-01
 i=  32 alpha=0.259 err=0.373 loss=2.41e-01
 i=  48 alpha=0.172 err=0.415 loss=1.75e-01
 i=  64 alpha=0.188 err=0.407 loss=1.33e-01
 i=  80 alpha=0.171 err=0.416 loss=1.00e-01
 i=  96 alpha=0.172 err=0.415 loss=7.92e-02
 i= 112 alpha=0.176 err=0.413 loss=6.26e-02
 i= 128 alpha=0.162 err=0.420 loss=5.04e-02
Done training err=0.0087 fp=0.0049 fn=0.0125 (t=15.1s).
Done training stage 1 (time=6070s).
---------------------------------------------------------------------------
Training stage 2
Sampled 5000 windows from 512 images.
Done sampling windows (time=610s).
Extracting features... done (time=6s).
Training AdaBoost: nWeak=512 nFtrs=5819 pos=28496 neg=10000
 i=  16 alpha=0.245 err=0.380 loss=4.70e-01
 i=  32 alpha=0.183 err=0.410 loss=3.24e-01
 i=  48 alpha=0.155 err=0.423 loss=2.50e-01
 i=  64 alpha=0.150 err=0.425 loss=2.02e-01
 i=  80 alpha=0.147 err=0.427 loss=1.65e-01
 i=  96 alpha=0.154 err=0.423 loss=1.37e-01
 i= 112 alpha=0.132 err=0.434 loss=1.14e-01
 i= 128 alpha=0.155 err=0.423 loss=9.53e-02
 i= 144 alpha=0.150 err=0.426 loss=8.15e-02
 i= 160 alpha=0.128 err=0.436 loss=6.96e-02
 i= 176 alpha=0.126 err=0.438 loss=6.01e-02
 i= 192 alpha=0.137 err=0.432 loss=5.19e-02
 i= 208 alpha=0.124 err=0.438 loss=4.49e-02
 i= 224 alpha=0.118 err=0.441 loss=3.89e-02
 i= 240 alpha=0.141 err=0.430 loss=3.38e-02
 i= 256 alpha=0.118 err=0.441 loss=2.97e-02
 i= 272 alpha=0.127 err=0.437 loss=2.59e-02
 i= 288 alpha=0.149 err=0.426 loss=2.26e-02
 i= 304 alpha=0.147 err=0.427 loss=1.96e-02
 i= 320 alpha=0.122 err=0.439 loss=1.72e-02
 i= 336 alpha=0.121 err=0.440 loss=1.51e-02
 i= 352 alpha=0.127 err=0.437 loss=1.32e-02
 i= 368 alpha=0.146 err=0.428 loss=1.15e-02
 i= 384 alpha=0.127 err=0.437 loss=9.94e-03
 i= 400 alpha=0.156 err=0.423 loss=8.66e-03
 i= 416 alpha=0.120 err=0.440 loss=7.62e-03
 i= 432 alpha=0.132 err=0.435 loss=6.68e-03
 i= 448 alpha=0.103 err=0.449 loss=5.87e-03
 i= 464 alpha=0.134 err=0.434 loss=5.14e-03
 i= 480 alpha=0.125 err=0.438 loss=4.51e-03
 i= 496 alpha=0.116 err=0.442 loss=3.99e-03
 i= 512 alpha=0.109 err=0.446 loss=3.51e-03
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=51.5s).
Done training stage 2 (time=669s).
---------------------------------------------------------------------------
Training stage 3
Sampled 5000 windows from 640 images.
Done sampling windows (time=134s).
Extracting features... done (time=6s).
Training AdaBoost: nWeak=2048 nFtrs=5819 pos=28496 neg=10000
 i=  16 alpha=0.220 err=0.392 loss=4.99e-01
 i=  32 alpha=0.174 err=0.414 loss=3.67e-01
 i=  48 alpha=0.164 err=0.419 loss=2.99e-01
 i=  64 alpha=0.157 err=0.422 loss=2.48e-01
 i=  80 alpha=0.128 err=0.437 loss=2.11e-01
 i=  96 alpha=0.133 err=0.434 loss=1.84e-01
 i= 112 alpha=0.137 err=0.432 loss=1.59e-01
 i= 128 alpha=0.123 err=0.439 loss=1.40e-01
 i= 144 alpha=0.133 err=0.434 loss=1.22e-01
 i= 160 alpha=0.126 err=0.438 loss=1.08e-01
 i= 176 alpha=0.135 err=0.433 loss=9.49e-02
 i= 192 alpha=0.115 err=0.443 loss=8.41e-02
 i= 208 alpha=0.133 err=0.434 loss=7.43e-02
 i= 224 alpha=0.128 err=0.436 loss=6.64e-02
 i= 240 alpha=0.134 err=0.434 loss=5.84e-02
 i= 256 alpha=0.117 err=0.442 loss=5.24e-02
 i= 272 alpha=0.113 err=0.444 loss=4.66e-02
 i= 288 alpha=0.137 err=0.432 loss=4.17e-02
 i= 304 alpha=0.100 err=0.450 loss=3.73e-02
 i= 320 alpha=0.102 err=0.449 loss=3.34e-02
 i= 336 alpha=0.134 err=0.433 loss=2.99e-02
 i= 352 alpha=0.128 err=0.436 loss=2.68e-02
 i= 368 alpha=0.120 err=0.441 loss=2.42e-02
 i= 384 alpha=0.114 err=0.443 loss=2.18e-02
 i= 400 alpha=0.114 err=0.443 loss=1.96e-02
 i= 416 alpha=0.132 err=0.435 loss=1.76e-02
 i= 432 alpha=0.102 err=0.449 loss=1.59e-02
 i= 448 alpha=0.109 err=0.445 loss=1.42e-02
 i= 464 alpha=0.109 err=0.446 loss=1.28e-02
 i= 480 alpha=0.110 err=0.445 loss=1.16e-02
 i= 496 alpha=0.113 err=0.444 loss=1.05e-02
 i= 512 alpha=0.108 err=0.446 loss=9.48e-03
 i= 528 alpha=0.122 err=0.439 loss=8.53e-03
 i= 544 alpha=0.112 err=0.444 loss=7.70e-03
 i= 560 alpha=0.113 err=0.444 loss=6.99e-03
 i= 576 alpha=0.120 err=0.440 loss=6.31e-03
 i= 592 alpha=0.101 err=0.450 loss=5.70e-03
 i= 608 alpha=0.114 err=0.443 loss=5.16e-03
 i= 624 alpha=0.103 err=0.449 loss=4.69e-03
 i= 640 alpha=0.104 err=0.448 loss=4.25e-03
 i= 656 alpha=0.103 err=0.449 loss=3.85e-03
 i= 672 alpha=0.122 err=0.439 loss=3.48e-03
 i= 688 alpha=0.100 err=0.450 loss=3.16e-03
 i= 704 alpha=0.118 err=0.441 loss=2.87e-03
 i= 720 alpha=0.113 err=0.444 loss=2.59e-03
 i= 736 alpha=0.109 err=0.446 loss=2.35e-03
 i= 752 alpha=0.105 err=0.448 loss=2.14e-03
 i= 768 alpha=0.110 err=0.445 loss=1.94e-03
 i= 784 alpha=0.104 err=0.448 loss=1.76e-03
 i= 800 alpha=0.112 err=0.444 loss=1.59e-03
 i= 816 alpha=0.113 err=0.444 loss=1.44e-03
 i= 832 alpha=0.102 err=0.449 loss=1.31e-03
 i= 848 alpha=0.116 err=0.442 loss=1.19e-03
 i= 864 alpha=0.098 err=0.451 loss=1.08e-03
 i= 880 alpha=0.125 err=0.438 loss=9.62e-04
 i= 896 alpha=0.125 err=0.438 loss=8.71e-04
 i= 912 alpha=0.117 err=0.442 loss=7.78e-04
 i= 928 alpha=0.106 err=0.447 loss=7.05e-04
 i= 944 alpha=0.115 err=0.443 loss=6.42e-04
 i= 960 alpha=0.102 err=0.449 loss=5.81e-04
 i= 976 alpha=0.100 err=0.450 loss=5.30e-04
 i= 992 alpha=0.102 err=0.449 loss=4.80e-04
 i=1008 alpha=0.106 err=0.447 loss=4.34e-04
 i=1024 alpha=0.111 err=0.445 loss=3.93e-04
 i=1040 alpha=0.122 err=0.439 loss=3.54e-04
 i=1056 alpha=0.106 err=0.447 loss=3.22e-04
 i=1072 alpha=0.119 err=0.441 loss=2.90e-04
 i=1088 alpha=0.114 err=0.443 loss=2.62e-04
 i=1104 alpha=0.108 err=0.446 loss=2.37e-04
 i=1120 alpha=0.113 err=0.444 loss=2.15e-04
 i=1136 alpha=0.115 err=0.443 loss=1.94e-04
 i=1152 alpha=0.116 err=0.442 loss=1.76e-04
 i=1168 alpha=0.113 err=0.444 loss=1.59e-04
 i=1184 alpha=0.120 err=0.440 loss=1.44e-04
 i=1200 alpha=0.117 err=0.442 loss=1.32e-04
 i=1216 alpha=0.105 err=0.448 loss=1.19e-04
 i=1232 alpha=0.120 err=0.440 loss=1.07e-04
 i=1248 alpha=0.119 err=0.441 loss=9.67e-05
 i=1264 alpha=0.107 err=0.447 loss=8.76e-05
 i=1280 alpha=0.105 err=0.448 loss=7.95e-05
 i=1296 alpha=0.091 err=0.454 loss=7.20e-05
 i=1312 alpha=0.119 err=0.441 loss=6.47e-05
 i=1328 alpha=0.109 err=0.446 loss=5.85e-05
 i=1344 alpha=0.113 err=0.444 loss=5.31e-05
 i=1360 alpha=0.116 err=0.442 loss=4.80e-05
 i=1376 alpha=0.113 err=0.444 loss=4.34e-05
 i=1392 alpha=0.101 err=0.449 loss=3.94e-05
 i=1408 alpha=0.117 err=0.442 loss=3.56e-05
 i=1424 alpha=0.109 err=0.446 loss=3.22e-05
 i=1440 alpha=0.118 err=0.441 loss=2.90e-05
 i=1456 alpha=0.109 err=0.446 loss=2.62e-05
 i=1472 alpha=0.104 err=0.448 loss=2.38e-05
 i=1488 alpha=0.100 err=0.450 loss=2.17e-05
 i=1504 alpha=0.107 err=0.447 loss=1.96e-05
 i=1520 alpha=0.112 err=0.444 loss=1.76e-05
 i=1536 alpha=0.107 err=0.447 loss=1.58e-05
 i=1552 alpha=0.112 err=0.444 loss=1.43e-05
 i=1568 alpha=0.102 err=0.449 loss=1.28e-05
 i=1584 alpha=0.119 err=0.441 loss=1.16e-05
 i=1600 alpha=0.107 err=0.447 loss=1.05e-05
 i=1616 alpha=0.119 err=0.441 loss=9.48e-06
 i=1632 alpha=0.107 err=0.447 loss=8.56e-06
 i=1648 alpha=0.107 err=0.447 loss=7.79e-06
 i=1664 alpha=0.107 err=0.447 loss=7.06e-06
 i=1680 alpha=0.108 err=0.446 loss=6.42e-06
 i=1696 alpha=0.110 err=0.445 loss=5.82e-06
 i=1712 alpha=0.102 err=0.449 loss=5.25e-06
 i=1728 alpha=0.120 err=0.440 loss=4.76e-06
 i=1744 alpha=0.124 err=0.438 loss=4.30e-06
 i=1760 alpha=0.103 err=0.449 loss=3.90e-06
 i=1776 alpha=0.102 err=0.449 loss=3.56e-06
 i=1792 alpha=0.098 err=0.451 loss=3.24e-06
 i=1808 alpha=0.120 err=0.441 loss=2.94e-06
 i=1824 alpha=0.106 err=0.447 loss=2.68e-06
 i=1840 alpha=0.108 err=0.446 loss=2.42e-06
 i=1856 alpha=0.111 err=0.445 loss=2.18e-06
 i=1872 alpha=0.111 err=0.445 loss=1.97e-06
 i=1888 alpha=0.107 err=0.447 loss=1.81e-06
 i=1904 alpha=0.105 err=0.448 loss=1.65e-06
 i=1920 alpha=0.110 err=0.445 loss=1.49e-06
 i=1936 alpha=0.108 err=0.446 loss=1.36e-06
 i=1952 alpha=0.112 err=0.444 loss=1.24e-06
 i=1968 alpha=0.099 err=0.451 loss=1.13e-06
 i=1984 alpha=0.109 err=0.445 loss=1.02e-06
 i=2000 alpha=0.096 err=0.452 loss=9.30e-07
 i=2016 alpha=0.108 err=0.446 loss=8.36e-07
 i=2032 alpha=0.119 err=0.441 loss=7.56e-07
 i=2048 alpha=0.106 err=0.447 loss=6.85e-07
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=205.7s).
Done training stage 3 (time=347s).
---------------------------------------------------------------------------
Done training (time=7796s).
